{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15d96823-a283-477d-8a4c-f89af4a5d071",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# HDDLGym Tutorial\n",
    "Welcome to a walkthrough of HDDLGym system. This notebook provides the guide from create and modifying HDDL domains to run and train RL policy for hierarchical planning problem in multi-agent settings. \n",
    "\n",
    "Table of Contents\n",
    "1. [Modify HDDL files to adapt to the HDDLGym system](#1-Modify-HDDL-files-to-adapt-to-the-HDDLGym-system)\n",
    "\n",
    "2. [Test HDDL domain and problem with random exploration](#2-Test-HDDL-domain-and-problem-files-with-random-exploration)\n",
    "\n",
    "3. [Design a RL policy](#3-Design-a-RL-policy)\n",
    "\n",
    "4. [Train RL policy](#4-Train-RL-policy)\n",
    "\n",
    "5. [Deploy RL policy](#5-Deploy-RL-policy)\n",
    "\n",
    "6. [Extra - Overcooked Policy Visualization Tutorial](#Overcooked-Policy-Visualization-Tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d40543f-6240-4f44-be5d-ee5ab2042d28",
   "metadata": {},
   "source": [
    "# Install dependencies\n",
    "For majority of features of HDDLGym, we need general python packages such as gym, torch, tensorboard, etc. \n",
    "\n",
    "Additionally, for required packages to run demo such as Overcooked, please look at _requirements.txt_.\n",
    "\n",
    "On the other hand, you can use Docker to run the code. In this case, please make sure to adjust the command in _Dockerfile_ to match your purpose.  \n",
    "\n",
    "[back to top](#HDDLGym-Tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19d47596-9aad-43e8-9b5c-20cd7a58a3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in /home/nicole/miniconda3/lib/python3.8/site-packages (0.23.1)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /home/nicole/miniconda3/lib/python3.8/site-packages (from gym) (1.23.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/nicole/miniconda3/lib/python3.8/site-packages (from gym) (3.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /home/nicole/miniconda3/lib/python3.8/site-packages (from gym) (0.0.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.10.0 in /home/nicole/miniconda3/lib/python3.8/site-packages (from gym) (6.8.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/nicole/miniconda3/lib/python3.8/site-packages (from importlib-metadata>=4.10.0->gym) (3.17.0)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: gymnasium in /home/nicole/miniconda3/lib/python3.8/site-packages (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/nicole/miniconda3/lib/python3.8/site-packages (from gymnasium) (1.23.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/nicole/miniconda3/lib/python3.8/site-packages (from gymnasium) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/nicole/miniconda3/lib/python3.8/site-packages (from gymnasium) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/nicole/miniconda3/lib/python3.8/site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /home/nicole/miniconda3/lib/python3.8/site-packages (from gymnasium) (6.8.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/nicole/miniconda3/lib/python3.8/site-packages (from importlib-metadata>=4.8.0->gymnasium) (3.17.0)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: torch in /home/nicole/miniconda3/lib/python3.8/site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in /home/nicole/miniconda3/lib/python3.8/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/nicole/miniconda3/lib/python3.8/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/nicole/miniconda3/lib/python3.8/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/nicole/miniconda3/lib/python3.8/site-packages (from torch) (2.8.5)\n",
      "Requirement already satisfied: jinja2 in /home/nicole/miniconda3/lib/python3.8/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/nicole/miniconda3/lib/python3.8/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/nicole/miniconda3/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/nicole/miniconda3/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/nicole/miniconda3/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/nicole/miniconda3/lib/python3.8/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/nicole/miniconda3/lib/python3.8/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/nicole/miniconda3/lib/python3.8/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/nicole/miniconda3/lib/python3.8/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/nicole/miniconda3/lib/python3.8/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/nicole/miniconda3/lib/python3.8/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/nicole/miniconda3/lib/python3.8/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/nicole/miniconda3/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/nicole/miniconda3/lib/python3.8/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/nicole/miniconda3/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.77)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/nicole/miniconda3/lib/python3.8/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/nicole/miniconda3/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: tensorboard in /home/nicole/miniconda3/lib/python3.8/site-packages (2.14.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/nicole/miniconda3/lib/python3.8/site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/nicole/miniconda3/lib/python3.8/site-packages (from tensorboard) (1.70.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/nicole/miniconda3/lib/python3.8/site-packages (from tensorboard) (2.38.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/nicole/miniconda3/lib/python3.8/site-packages (from tensorboard) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/nicole/miniconda3/lib/python3.8/site-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/nicole/miniconda3/lib/python3.8/site-packages (from tensorboard) (1.23.2)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /home/nicole/miniconda3/lib/python3.8/site-packages (from tensorboard) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/nicole/miniconda3/lib/python3.8/site-packages (from tensorboard) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/nicole/miniconda3/lib/python3.8/site-packages (from tensorboard) (61.2.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/nicole/miniconda3/lib/python3.8/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/nicole/miniconda3/lib/python3.8/site-packages (from tensorboard) (3.0.6)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/nicole/miniconda3/lib/python3.8/site-packages (from tensorboard) (0.41.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/nicole/miniconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/nicole/miniconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/nicole/miniconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/nicole/miniconda3/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/nicole/miniconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard) (6.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/nicole/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/nicole/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/nicole/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nicole/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (2022.9.24)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/nicole/miniconda3/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/nicole/miniconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.17.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/nicole/miniconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/nicole/miniconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install gym\n",
    "!pip install gymnasium\n",
    "!pip install torch\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0462310a-53ae-4e2a-b98a-5e3e529e5841",
   "metadata": {},
   "source": [
    "# 1 Modify HDDL files to adapt to the HDDLGym system\n",
    "\\(with an example of Transport domain\\)\n",
    "As discussed in the paper, several modications are required before applying HDDL domain and problem files to the HDDLGym system.\n",
    "\n",
    "- Identify agent:\n",
    "    \n",
    "    Identify and explicitly define \"agent\" as a type or a supertype.\n",
    "\n",
    "    For example, in Transport domain, 'vehicle' can be classified as an 'agent'.\n",
    "\n",
    "    If the domain has no type that can be classified as an agent, simply include 'agent' in the types block.\n",
    "\n",
    "- Add agent to parameters of agent-related actions:\n",
    "\n",
    "    For _:action_ blocks that defined agent-related actions, please ensure to include 'agent' or agent's type in its parameters.\n",
    "\n",
    "- Add effects to tasks\n",
    "\n",
    "    Each _:task_ block are required to include _effects_. \n",
    "\n",
    "- Add none-action to the domain:\n",
    "\n",
    "    Please ensure there is a block of none-action in the domain file. If there is similar action (but different name), then replace it with the none-action. The none-action block should be:\n",
    "\n",
    "\n",
    "    (:action none \n",
    "\n",
    ">:parameters (?agent - agent) \n",
    "\n",
    ">:precondition () \n",
    "\n",
    ">:effect ()\n",
    "    )\n",
    "\n",
    "### Checking if HDDL domain files meet HDDLGym format requirements:\n",
    "Use the following code to check your the HDDL domain files\n",
    "\n",
    "[back to top](#HDDLGym-Tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc82512d-22f8-4e64-9130-c69accaf8156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some helper functions \n",
    "import re\n",
    "import os\n",
    "def check_none_action_defined_correctly(file_path, with_none_name=True):\n",
    "    '''\n",
    "    check if in the HDDL file (file_path), the none action is defined correctly\n",
    "    '''\n",
    "    temp_file = file_path.split('.hddl')[0] + '_temp.hddl'\n",
    "    remove_comments_from_pddl(file_path,temp_file)\n",
    "    if with_none_name:\n",
    "        # Define a regex pattern to match the 'none' action with strict conditions\n",
    "        pattern = re.compile(\n",
    "            r\"\\(:action\\s+none\\s*\"  # Match the action definition\n",
    "            r\":parameters\\s*\\(\\?\\w+\\s*-\\s*agent\\)\\s*\"  # Match any parameter name before \"- agent\"\n",
    "            r\":precondition\\s*\\(\\)\\s*\"  # Match empty precondition\n",
    "            r\":effect\\s*\\(\\)\\s*\"  # Match empty effect\n",
    "            r\"\\)\",  # Closing parenthesis\n",
    "            re.MULTILINE\n",
    "        )\n",
    "    else:\n",
    "        pattern = re.compile(\n",
    "            r\"\\(:action\\s+([^\\s]+)\\s*\"  # Capture action name (group 1)\n",
    "            r\":parameters\\s*\\(\\?\\w+\\s*-\\s*agent\\)\\s*\"  # Match any parameter name before \"- agent\"\n",
    "            r\":precondition\\s*\\(\\)\\s*\"  # Match empty precondition\n",
    "            r\":effect\\s*\\(\\)\\s*\"  # Match empty effect\n",
    "            r\"\\)\",  # Closing parenthesis\n",
    "            re.MULTILINE\n",
    "        )\n",
    "\n",
    "    # Read the PDDL file\n",
    "    with open(temp_file, \"r\") as file:\n",
    "        content = file.read()\n",
    "    # remove temp_file:\n",
    "    if os.path.exists(temp_file):\n",
    "        os.remove(temp_file)\n",
    "    # Check if the pattern exists in the HDDL file\n",
    "    if with_none_name:\n",
    "        if pattern.search(content):\n",
    "            # print(\"The action `none` is correctly defined in the HDDL file.\")\n",
    "            return True\n",
    "        else:\n",
    "            # print(\"The action `none` is missing or incorrectly formatted.\")\n",
    "            return False\n",
    "    else:\n",
    "        matches = pattern.findall(content)\n",
    "        if matches:\n",
    "            ans_str = \"Found similar action(s) to none-action but with different name:\\n\"\n",
    "            for action in matches:\n",
    "                ans_str += f\" {action}\\n\"\n",
    "                if len(matches) == 1:\n",
    "                    ans_str += f\"---> Suggest change its name to none: '{action}' ==> 'none'\"\n",
    "            if len(matches) > 1:\n",
    "                ans_str += \"---> Suggest combine these similar actions into one action and name it 'none'.\"\n",
    "            return ans_str\n",
    "        else:\n",
    "            return \"No similar action to none-action\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a827b77b-9339-4443-b4ba-43fb950ecd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Checking if the domain file has 'agent' in the type block ***\n",
      "'agent' is a type or supertype.\n",
      "\n",
      "***Checking if agent is in parameters of actions ***\n",
      "No agent actions:  ['cooking', 'a-complete-cooking']\n",
      "---> Suggest adding '?agent - agent' in the parameter if any action above is not an environment action\n",
      "\n",
      "*** Checking none-action ***\n",
      "No none-action is defined as required.\n",
      "Found similar action(s) to none-action but with different name:\n",
      " noop\n",
      "---> Suggest change its name to none: 'noop' ==> 'none'\n",
      "\n",
      "*** Checking general format of action, task, and method blocks ***\n",
      "HDDL file format is correct.\n"
     ]
    }
   ],
   "source": [
    "from HDDL_files.modify_hddl_domain_for_HDDLGym import check_hddl_format, parse_types, is_agent_in_hierarchy,find_actions_without_agent\n",
    "import os\n",
    "from pathlib import Path\n",
    "script_dir = Path(os.getcwd())\n",
    "# TO DO: Modify the domain_file_dir to check if your HDDL domain file meets requirements\n",
    "domain_file = str(script_dir / \"HDDL_files/test_input_modify_overcooked.hddl\")\n",
    "problem_file = str(script_dir / \"HDDL_files/Overcooked_specialization/overcooked_short_prob2.hddl\")\n",
    "# End To Do\n",
    "\n",
    "# Assign directory for the valid domain file:\n",
    "\n",
    "# Remove all comments before checking the format:\n",
    "domain_file_no_comments = domain_file.split('.hddl')[0] + '_no_comments.hddl'\n",
    "problem_file_no_comments = problem_file.split('.hddl')[0] + '_no_comments.hddl'\n",
    "remove_comments_from_pddl(domain_file, domain_file_no_comments)\n",
    "remove_comments_from_pddl(problem_file, problem_file_no_comments)\n",
    "\n",
    "# Check if the domain file has 'agent' in the type:\n",
    "print(\"*** Checking if the domain file has 'agent' in the type block ***\")\n",
    "type_hierarchy = parse_types(domain_file_no_comments)\n",
    "if type_hierarchy:\n",
    "    is_agent_in_hierarchy(type_hierarchy)\n",
    "\n",
    "# Agent-related actions and environment actions:\n",
    "print(\"\\n***Checking if agent is in parameters of actions ***\")\n",
    "no_agent_actions = find_actions_without_agent(domain_file_no_comments)\n",
    "print(\"No agent actions: \", no_agent_actions)\n",
    "if len(no_agent_actions):\n",
    "    print(\"---> Suggest adding '?agent - agent' in the parameter if any action above is not an environment action!\")\n",
    "\n",
    "# Check None-action:\n",
    "print(\"\\n*** Checking none-action ***\")\n",
    "if check_none_action_defined_correctly(domain_file_no_comments, with_none_name = True):\n",
    "    print(\"The none action is correctly defined.\")\n",
    "else:\n",
    "    print(\"No none-action is defined as required.\")\n",
    "    error = check_none_action_defined_correctly(domain_file_no_comments, with_none_name=False)\n",
    "    print(error)\n",
    "\n",
    "# Check if the domain file has correct number of parentheses, actions, tasks, methods with correct format:\n",
    "print(\"\\n*** Checking general format of action, task, and method blocks ***\")\n",
    "check_hddl_format(domain_file_no_comments)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d86f824-e12d-48cf-aa19-b9c9e6d423a2",
   "metadata": {},
   "source": [
    "# 2 Test HDDL domain and problem files with random exploration\n",
    "\n",
    "To test if the HDDLGym Planner working with the HDDL domain and problem files, we run the environment with random exploration\n",
    "\n",
    "[back to top](#HDDLGym-Tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cefb651-b03c-46cb-b2df-e9aed24c64c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start evaluating policy ...\n",
      "action_dict {'chef1': 'none chef1', 'chef2': 'none chef2'}\n",
      "action_dict {'chef1': 'none chef1', 'chef2': 'a-interact chef2 onion-pile empty onion onion onion'}\n",
      "action_dict {'chef1': 'none chef1', 'chef2': 'none chef2'}\n",
      "action_dict {'chef1': 'none chef1', 'chef2': 'none chef2'}\n",
      "action_dict {'chef1': 'none chef1', 'chef2': 'a-interact chef2 pot1 onion empty empty onion-1'}\n",
      "action_dict {'chef1': 'a-interact chef1 pot1 empty empty onion-1 cooking-soup-1-onion', 'chef2': 'none chef2'}\n",
      "action_dict {'chef1': 'a-interact chef1 bowl-pile empty bowl bowl bowl', 'chef2': 'none chef2'}\n",
      "action_dict {'chef1': 'wait chef1 pot1 cooking-soup-1-onion-stage3 cooking-soup-1-onion-stage4', 'chef2': 'none chef2'}\n",
      "action_dict {'chef1': 'none chef1', 'chef2': 'none chef2'}\n",
      "action_dict {'chef1': 'none chef1', 'chef2': 'none chef2'}\n",
      "action_dict {'chef1': 'none chef1', 'chef2': 'none chef2'}\n",
      "action_dict {'chef1': 'none chef1', 'chef2': 'none chef2'}\n",
      "action_dict {'chef1': 'none chef1', 'chef2': 'none chef2'}\n",
      "action_dict {'chef1': 'a-interact chef1 pot1 bowl soup-1-onion soup-1-onion empty', 'chef2': 'none chef2'}\n",
      "action_dict {'chef1': 'a-interact chef1 delivery soup-1-onion empty empty soup-1-onion', 'chef2': 'none chef2'}\n",
      "Evaluation turn 0 completed ['make-soup soup-1-onion delivery'] after 15 steps, getting score of 70\n",
      "\n",
      "Hierarchies Record for turn  0\n",
      "[['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'add-ingredient pot1 onion onion-1', 'm-add-ingredient-1-onion pot1 onion onion-pile onion-1 empty', 'none chef1'], ['none chef2']]\n",
      "--\n",
      "{'chef1': 'none chef1', 'chef2': 'none chef2'}\n",
      "[['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'add-ingredient pot1 onion onion-1', 'm-add-ingredient-1-onion pot1 onion onion-pile onion-1 empty', 'none chef1'], ['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'add-ingredient pot1 onion onion-1', 'm-add-ingredient-1-onion pot1 onion onion-pile onion-1 empty', 't-interact chef2 onion-pile onion onion', 'm-interact-direct chef2 onion-pile empty onion onion onion', 'a-interact chef2 onion-pile empty onion onion onion']]\n",
      "--\n",
      "{'chef1': 'none chef1', 'chef2': 'a-interact chef2 onion-pile empty onion onion onion'}\n",
      "[['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'add-ingredient pot1 onion onion-1', 'm-add-ingredient-1-onion pot1 onion onion-pile onion-1 empty', 'none chef1'], ['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'add-ingredient pot1 onion onion-1', 'm-add-ingredient-1-onion pot1 onion onion-pile onion-1 empty', 't-interact chef2 pot1 empty onion-1', 'm-interact-direct chef2 pot1 onion empty empty onion-1', 'none chef2']]\n",
      "--\n",
      "{'chef1': 'none chef1', 'chef2': 'none chef2'}\n",
      "[['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'add-ingredient pot1 onion onion-1', 'm-add-ingredient-1-onion pot1 onion onion-pile onion-1 empty', 'none chef1'], ['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'add-ingredient pot1 onion onion-1', 'm-add-ingredient-1-onion pot1 onion onion-pile onion-1 empty', 't-interact chef2 pot1 empty onion-1', 'm-interact-direct chef2 pot1 onion empty empty onion-1', 'none chef2']]\n",
      "--\n",
      "{'chef1': 'none chef1', 'chef2': 'none chef2'}\n",
      "[['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'add-ingredient pot1 onion onion-1', 'm-add-ingredient-1-onion pot1 onion onion-pile onion-1 empty', 'none chef1'], ['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'add-ingredient pot1 onion onion-1', 'm-add-ingredient-1-onion pot1 onion onion-pile onion-1 empty', 't-interact chef2 pot1 empty onion-1', 'm-interact-direct chef2 pot1 onion empty empty onion-1', 'a-interact chef2 pot1 onion empty empty onion-1']]\n",
      "--\n",
      "{'chef1': 'none chef1', 'chef2': 'a-interact chef2 pot1 onion empty empty onion-1'}\n",
      "[['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'cook pot1 onion-1 cooking-soup-1-onion', 'm-cook pot1 onion-1 cooking-soup-1-onion chef1 empty', 'a-interact chef1 pot1 empty empty onion-1 cooking-soup-1-onion'], ['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'cook pot1 onion-1 cooking-soup-1-onion', 'm-cook pot1 onion-1 cooking-soup-1-onion chef2 empty', 'none chef2']]\n",
      "--\n",
      "{'chef1': 'a-interact chef1 pot1 empty empty onion-1 cooking-soup-1-onion', 'chef2': 'none chef2'}\n",
      "[['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 't-interact chef1 bowl-pile bowl bowl', 'm-interact-direct chef1 bowl-pile empty bowl bowl bowl', 'a-interact chef1 bowl-pile empty bowl bowl bowl'], ['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 'none chef2']]\n",
      "--\n",
      "{'chef1': 'a-interact chef1 bowl-pile empty bowl bowl bowl', 'chef2': 'none chef2'}\n",
      "[['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 't-wait-cooking chef1 pot1 soup-1-onion', 'm-still-wait-cooking chef1 pot1 soup-1-onion cooking-soup-1-onion-stage3 cooking-soup-1-onion-stage4', 'wait chef1 pot1 cooking-soup-1-onion-stage3 cooking-soup-1-onion-stage4'], ['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 'none chef2']]\n",
      "--\n",
      "{'chef1': 'wait chef1 pot1 cooking-soup-1-onion-stage3 cooking-soup-1-onion-stage4', 'chef2': 'none chef2'}\n",
      "[['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 't-wait-cooking chef1 pot1 soup-1-onion', 'm-still-wait-cooking chef1 pot1 soup-1-onion cooking-soup-1-onion-stage3 cooking-soup-1-onion-stage4', 'none chef1'], ['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 'none chef2']]\n",
      "--\n",
      "{'chef1': 'none chef1', 'chef2': 'none chef2'}\n",
      "[['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 't-interact chef1 pot1 soup-1-onion empty', 'm-interact-direct chef1 pot1 bowl soup-1-onion soup-1-onion empty', 'none chef1'], ['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 'none chef2']]\n",
      "--\n",
      "{'chef1': 'none chef1', 'chef2': 'none chef2'}\n",
      "[['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 't-interact chef1 pot1 soup-1-onion empty', 'm-interact-direct chef1 pot1 bowl soup-1-onion soup-1-onion empty', 'none chef1'], ['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 'none chef2']]\n",
      "--\n",
      "{'chef1': 'none chef1', 'chef2': 'none chef2'}\n",
      "[['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 't-interact chef1 pot1 soup-1-onion empty', 'm-interact-direct chef1 pot1 bowl soup-1-onion soup-1-onion empty', 'none chef1'], ['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 'none chef2']]\n",
      "--\n",
      "{'chef1': 'none chef1', 'chef2': 'none chef2'}\n",
      "[['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 't-interact chef1 pot1 soup-1-onion empty', 'm-interact-direct chef1 pot1 bowl soup-1-onion soup-1-onion empty', 'none chef1'], ['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 'none chef2']]\n",
      "--\n",
      "{'chef1': 'none chef1', 'chef2': 'none chef2'}\n",
      "[['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 't-interact chef1 pot1 soup-1-onion empty', 'm-interact-direct chef1 pot1 bowl soup-1-onion soup-1-onion empty', 'a-interact chef1 pot1 bowl soup-1-onion soup-1-onion empty'], ['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 'none chef2']]\n",
      "--\n",
      "{'chef1': 'a-interact chef1 pot1 bowl soup-1-onion soup-1-onion empty', 'chef2': 'none chef2'}\n",
      "[['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 't-interact chef1 delivery empty soup-1-onion', 'm-interact-direct chef1 delivery soup-1-onion empty empty soup-1-onion', 'a-interact chef1 delivery soup-1-onion empty empty soup-1-onion'], ['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 'none chef2']]\n",
      "--\n",
      "{'chef1': 'a-interact chef1 delivery soup-1-onion empty empty soup-1-onion', 'chef2': 'none chef2'}\n",
      "Episode reward of evaluating episode 0 is 70\n",
      "SCORE:  70\n"
     ]
    }
   ],
   "source": [
    "from learning_methods import evaluate_policy\n",
    "from hddl_env import HDDLEnv\n",
    "from HDDL_files.modify_hddl_domain_for_HDDLGym import remove_comments_from_pddl\n",
    "from learning_methods import PPO_discrete\n",
    "import torch\n",
    "\n",
    "# TO DO: replace the domain_file and problem_file below with your files    \n",
    "domain_file = \"HDDL_files/Overcooked_specialization/overcooked_short_domain.hddl\"\n",
    "problem_file = \"HDDL_files/Overcooked_specialization/overcooked_short_prob2.hddl\"\n",
    "# End TO DO\n",
    "\n",
    "class Parameters():\n",
    "    # Mimicking the arguments of parse_arguments for main_train.py\n",
    "    def __init__(self, domain, problem):\n",
    "        self.dvc = 'cpu' # running device: cuda or cpu\n",
    "        self.domain = domain # directory to domain file\n",
    "        self.problem = problem # directory to problem file\n",
    "        self.state_dim = None # state dimension\n",
    "        self.action_dim = None # action dimension\n",
    "        self.use_central_planner = False\n",
    "        self.planner_time_limit = 5\n",
    "        self.write = False\n",
    "        self.Loadmodel = False\n",
    "        self.debug = False\n",
    "        # related to training:\n",
    "        self.net_width = 64\n",
    "        self.lr = 1e-4\n",
    "        self.T_horizon = 2048\n",
    "        self.seed = 502\n",
    "        self.activation = 'tanh'\n",
    "        \n",
    "\n",
    "\n",
    "domain_file_no_comments = domain_file.split('.hddl')[0] + '_no_comments.hddl'\n",
    "problem_file_no_comments = problem_file.split('.hddl')[0] + '_no_comments.hddl'\n",
    "remove_comments_from_pddl(domain_file, domain_file_no_comments)\n",
    "remove_comments_from_pddl(problem_file, problem_file_no_comments)\n",
    "opt = Parameters(domain=domain_file_no_comments, problem=problem_file_no_comments)\n",
    "\n",
    "\n",
    "class RandomPolicy():\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "\n",
    "    def select_action(self, s, deterministic=False, value=False):\n",
    "        # regardless deterministic or not, it is still a random process\n",
    "        probabilities = torch.rand(self.action_dim)  # Generate random values\n",
    "        probabilities /= probabilities.sum()  # Normalize to sum to 1\n",
    "        if value:\n",
    "            return probabilities\n",
    "        else:\n",
    "            return argmax\n",
    "\n",
    "\n",
    "###\n",
    "env = HDDLEnv(opt.domain, opt.problem)\n",
    "opt.state_dim = env.observation_space.n\n",
    "opt.action_dim = env.action_space.n\n",
    "# Two way to do random exploration:\n",
    "# 1. Use PPO_discrete when it is just randomly initiated, when the weights are not trained.\n",
    "# policy = PPO_discrete(**vars(opt)).to(opt.dvc)\n",
    "# 2. to create a RandomPolicy as follow:\n",
    "policy = RandomPolicy(opt.state_dim, opt.action_dim) # random policy defined above\n",
    "score = evaluate_policy(env, policy, turns = 1, opt=opt)\n",
    "print('SCORE: ', score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3edf400-9a5f-4d08-9057-7163c12e7583",
   "metadata": {},
   "source": [
    "# 3 Design a RL policy\n",
    "\n",
    "Designing a RL policy is a feature that the HDDLGym would like to support. The current version of HDDLGym offer PPO_discrete policy. Its input (observation) is a one-hot coded array of dynamic grounded predicates, lifted operators and objects of all agents' previous action hierarchies.\n",
    "\n",
    "Navigating to the file **learning_methods.py**, users can modify contents of functions in the file to alternate the observation and action space, design of RL models, training methods, evaluating methods, ect., as long as the function names remain the same.\n",
    "\n",
    "Following is some simple examples of modifying functions in learning_methods.py to change different components of the design of RL policy.\n",
    "\n",
    "**RL model**\n",
    "\n",
    "To change the RL model, make sure the class of new model, please ensure to modify the following function accordingly:\n",
    "- For just deploying the policy (no training): \\_\\_init__, select_action\n",
    "- For both deploying and training: \\_\\_init__, select_action, to, train, put_data, save, and load\n",
    "\n",
    "[back to top](#HDDLGym-Tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "087cfc1c-6b2a-459f-8de6-2611a546e878",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPolicy():\n",
    "    '''Notes: \n",
    "    This Random Policy is just for deploying the HDDLGym Planner with random exploration\n",
    "    Therefore, only implement __init__ and select_action method.\n",
    "    Other RL policies for require training like PPO_discrete should also implement other methods with similar features as functions in PPO_discrete \n",
    "    (such as train, put_data, save, and load)\n",
    "    '''\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "\n",
    "    def select_action(self, s, deterministic=False, value=False):\n",
    "        '''select action\n",
    "        input:\n",
    "        - s: an array representing the observation, or input for the policy\n",
    "        - deterministic: boolen, whether to choose action with the max value or\n",
    "                        to randomly choose it with weights are value of the policy\n",
    "        - value: boolean, whether to return the value of policy (probability list)\n",
    "        output:\n",
    "        - either probabilities or index of action with max probability (or value), depending on the value flag.\n",
    "        '''\n",
    "        # regardless deterministic or not, it is still a random process\n",
    "        probabilities = torch.rand(self.action_dim)  # Generate random values\n",
    "        probabilities /= probabilities.sum()  # Normalize to sum to 1\n",
    "        if value:\n",
    "            return probabilities\n",
    "        else:\n",
    "            max_index = probabilities.index(max(probabilities))\n",
    "            return max_index\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888d05f4-2319-483b-86cf-a507613dd79b",
   "metadata": {},
   "source": [
    "**Observation-Action Spaces**\n",
    "\n",
    "To change the observation and action spaces, modifying the contents of functions:\n",
    "- *get_observation_space*: specify what elements from the env_dictionary are in the observation. Here are some examples:\n",
    "  - \\[default\\] grounded dynamic predicates + lifted operators + related objects\n",
    "  - grounded dynamic predicates + lifted operators\n",
    "  - grounded predicates\n",
    "- *get_action_space*: specify what elements of the env_dictionary are in the action. Some examples are:\n",
    "  - \\[default\\] lifted operators + related objects\n",
    "  - lifted operators\n",
    "  - lifted method + lifted task + grounded action\n",
    "- *get_prob_from_prob_list*: get the probability of a grounded operator from the output of the policy (probability array)\n",
    "  - Depend on how the action space is designed, the probability of a grounded operator (g_oper) is calculated using the probabilities of elements that are relevant to the grounded operator (g_oper). For example:\n",
    "    - \\[default\\] logprob of g_oper =  mean(logprob of lifted operator of g_oper + logprob of objects in g_oper))\n",
    "    - if action space is grounded operators, then prob of g_oper can be directly get from the corresponding value in the probability array.\n",
    "\n",
    "- *get_observation_one_hot_vector*: generate observation array for the policy from the information of the current state (including current grounded predicates in the env, previous action or action hierarchy of agents). This function is modified according to how the observation space is defined.\n",
    "\n",
    "*Belows are default functions in learning_methods.py that are relevant to desgining observation-action spaces.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b736eb-9718-45e5-a708-cd371e0aff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change observation and action space:\n",
    "def get_observation_space(env_dictionary):\n",
    "    '''\n",
    "    This function return the size of observation space (or state space), which is also the output size of the RL policy\n",
    "    input:\n",
    "    - env_dictionary: environment dictionary, result of parsing the HDDL domain and problem file\n",
    "    output:\n",
    "    - gym.spaces.Discrete(n), with n is the len of observation\n",
    "    Note: \n",
    "    - in this approach, the observation space involves grounded dynamic predicate list, lifted action, and object list\n",
    "    '''\n",
    "    observation_space = gym.spaces.Discrete(n=len(env_dictionary['grounded dynamic predicate list'])+\\\n",
    "          len(env_dictionary['lifted operators list'])+len(env_dictionary['objects list']))\n",
    "\n",
    "    # Replace the above line of code by the below line, if just don't want to have objects list in observation:\n",
    "    # observation_space = gym.spaces.Discrete(n=len(env_dictionary['grounded dynamic predicate list'])+\\\n",
    "          # len(env_dictionary['lifted operators list']))\n",
    "    return observation_space\n",
    "\n",
    "def get_action_space(env_dictionary):\n",
    "    '''\n",
    "    This function return the size of action space, which is also the output size of the RL policy\n",
    "    input:\n",
    "    - env_dictionary: environment dictionary, result of parsing the HDDL domain and problem file\n",
    "    output:\n",
    "    - gym.spaces.Discrete(n), with n is the len of action\n",
    "    Note: \n",
    "    - in this approach, the action space involves lifted action and object list\n",
    "    '''\n",
    "    action_space = gym.spaces.Discrete(n=len(env_dictionary['lifted operators list'])+len(env_dictionary['objects list']))\n",
    "    # Use the below line of code instead if don't want include objects in action space\n",
    "    # action_space = gym.spaces.Discrete(n=len(env_dictionary['lifted operators list']))\n",
    "    return action_space\n",
    "\n",
    "def get_prob_from_prob_list(operator_str, prob_list, env_dictionary,device='cpu'):\n",
    "  '''This function provide probability value (prob) for the operator_str according to probabilities in the prob_list\n",
    "  inputs:\n",
    "  - operator_str: a string of operator_name + objects\n",
    "  - prob_list: a tensor, listing prob of lifted operators and objects\n",
    "  - env_dictionary: dictionary of environment's elements\n",
    "  outpus:\n",
    "  - prob: a float number of the probability of the operator_str\n",
    "  '''\n",
    "  oper_name, oper_obj = extract_object_list(operator_str)\n",
    "  oper_lifted_id = None\n",
    "  for lifted_ind, lifted_oper in enumerate(env_dictionary['lifted operators list']):\n",
    "    if lifted_oper.name == oper_name:\n",
    "      oper_lifted_id = lifted_ind\n",
    "  assert oper_lifted_id != None, \"Could not find lifted operators of oper {}\".format(operator_str)\n",
    "  indices_list = [oper_lifted_id]\n",
    "  for obj in oper_obj:\n",
    "    indices_list.append(env_dictionary['objects list'].index(obj) + len(env_dictionary['lifted operators list']))\n",
    "\n",
    "  relevant_prob_tensor = prob_list[indices_list]\n",
    "  prob = torch.exp(torch.div(torch.sum(torch.log(relevant_prob_tensor)),len(indices_list)+1e-20))\n",
    "  return prob\n",
    "\n",
    "\n",
    "def get_observation_one_hot_vector(current_state, all_operators, env_dictionary, device=False):\n",
    "    '''Get observation from current state and operators from action hierarchies\n",
    "    inputs:\n",
    "    - current_state: list of predicate\n",
    "    - all_operators: list of all operators\n",
    "    - env_dictionary: environment dictionary\n",
    "    - device: the device (CPU/GPU) to place the tensors on\n",
    "    output:\n",
    "    - observation: PyTorch tensor on the specified device\n",
    "    '''\n",
    "    if not device:\n",
    "      device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    state_num = enumerate_list(current_state, env_dictionary['grounded dynamic predicate list'])\n",
    "    state_num_tensor = torch.tensor(state_num, device=device, dtype=torch.float32)\n",
    "    lifted_operators_id, objects_id = convert_grounded_to_lifted_index(\n",
    "        all_operators, env_dictionary['lifted operators list'], env_dictionary['objects list']\n",
    "    )\n",
    "\n",
    "    lifted_operator_matrix = enumerate_index_to_binary_matrix(\n",
    "        lifted_operators_id, array_len=len(env_dictionary['lifted operators list']), device=device\n",
    "    )\n",
    "\n",
    "    object_matrix = enumerate_index_to_binary_matrix(\n",
    "        objects_id, array_len=len(env_dictionary['objects list']), device=device\n",
    "    )\n",
    "\n",
    "    observation = torch.cat([state_num_tensor, lifted_operator_matrix, object_matrix])\n",
    "\n",
    "    return observation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2049f613-d291-41a1-85eb-234eb898e640",
   "metadata": {},
   "source": [
    "# 4 Train RL policy\n",
    "\n",
    "For the default policy, we offer PPO_discrete, which is defined in **learning_methods.py**. To train the policy, simply call **main_train.py**:\n",
    "\n",
    "    python main_train.py\n",
    "\n",
    "There are parameters that users can either call with the command or modify in the file **main_train.py**. The common parameters are _domain_, _problem_ (file directions), and _dvc_ (training device option):\n",
    "\n",
    "    python main_train.py --domain <path/to/domain/file> --problem <path/to/problem/file> --dvc cpu\n",
    "\n",
    "### Here are optional arguments:\n",
    "| Argument | Parameter (opt.[])     | Description |\n",
    "|-----------------|-----------------|-------------|\n",
    "| `-h, --help`       |              | Show this help message and exit |\n",
    "| `--dvc` | `DVC`                       | Running device: `cuda` or `cpu` |\n",
    "| `--domain `|`DOMAIN`                 | Which domain HDDL file to load? |\n",
    "| `--problem `|`PROBLEM`               | Which problem HDDL file to load? |\n",
    "| `--write `|`WRITE`                   | Use SummaryWriter to record the training |\n",
    "| `--render `|`RENDER`                 | Render or Not |\n",
    "| `--Loadmodel `|`LOADMODEL`           | Load pretrained model or Not |\n",
    "| `--Model `|`MODEL`                   | Which model to load |\n",
    "| `--seed `|`SEED`                     | Random seed |\n",
    "| `--T_horizon `|`T_HORIZON`           | Length of long trajectory |\n",
    "| `--Max_train_steps `|`MAX_TRAIN_STEPS` | Max training steps |\n",
    "| `--save_interval `|`SAVE_INTERVAL`   | Model saving interval, in steps |\n",
    "| `--eval_interval `|`EVAL_INTERVAL`   | Model evaluating interval, in steps |\n",
    "| `--planner_time_limit `|`PLANNER_TIME_LIMIT` | The time limit (in seconds) for running the planner for each agent at each step |\n",
    "| `--gamma `|`GAMMA`                   | Discounted Factor |\n",
    "| `--lambd `|`LAMBD`                   | GAE Factor |\n",
    "| `--clip_rate `|`CLIP_RATE`           | PPO Clip rate |\n",
    "| `--K_epochs `|`K_EPOCHS`             | PPO update times |\n",
    "| `--net_width `|`NET_WIDTH`           | Hidden net width |\n",
    "| `--lr `|`LR`                         | Learning rate |\n",
    "| `--l2_reg `|`L2_REG`                 | L2 regularization coefficient for Critic |\n",
    "| `--batch_size `|`BATCH_SIZE`         | Length of sliced trajectory |\n",
    "| `--entropy_coef `|`ENTROPY_COEF`     | Entropy coefficient of Actor |\n",
    "| `--entropy_coef_decay `|`ENTROPY_COEF_DECAY` | Decay rate of `entropy_coef` |\n",
    "| `--adv_normalization `|`ADV_NORMALIZATION` | Advantage normalization |\n",
    "| `--max_episode `|`MAX_EPISODE`       | Max number of episodes in training |\n",
    "| `--max_step `|`MAX_STEP`             | Max number of steps in each episode |\n",
    "| `--epsilon `|`EPSILON`               | Epsilon |\n",
    "| `--activation `|`ACTIVATION`         | Activation function for learning model |\n",
    "| `--debug `|`DEBUG`                   | Debug mode or Not |\n",
    "| `--use_central_planner `|`USE_CENTRAL_PLANNER` | Whether to run centralized planner for multi-agent planning (default: `False`) |\n",
    "\n",
    "\n",
    "### Train custom RL policy:\n",
    "\n",
    "The file **main_train.py** in the codebase in used to train the default policy, PPO_discrete. However, if you design different RL methods, such as using different action spaces (lifted operation only) and/or observation space (use grounded predicates instead of dynamic grounded predicates), please ensure the observation and action space are modified in **learning_methods.py**, and the step of enumerating state and action in **main_train.py** are adjusted accordingly.\n",
    "\n",
    "\n",
    "[back to top](#HDDLGym-Tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5485059b-56fa-4b88-9566-1d6097a009e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(K_epochs=10, Loadmodel=False, Max_train_steps=50000000.0, Model=2, T_horizon=2048, activation='tanh', adv_normalization=False, batch_size=64, clip_rate=0.2, debug=False, domain='/home/nicole/MIT Dropbox/Ngoc La/PhD/Projects/HDDLGym_developing_rebuttal/HDDLGym_dev/HDDL_files/Overcooked_specialization/overcooked_short_domain.hddl', dvc=device(type='cpu'), entropy_coef=0.01, entropy_coef_decay=0.99, epsilon=1.0, eval_interval=1000.0, gamma=0.99, l2_reg=0, lambd=0.95, lr=0.0001, max_episode=50, max_step=25, net_width=64, planner_time_limit=5, problem='/home/nicole/MIT Dropbox/Ngoc La/PhD/Projects/HDDLGym_developing_rebuttal/HDDLGym_dev/HDDL_files/Overcooked_specialization/overcooked_short_prob2.hddl', render=False, save_interval=1000.0, seed=209, use_central_planner=False, write=False)\n",
      "Namespace(K_epochs=10, Loadmodel=False, Max_train_steps=50000000.0, Model=2, T_horizon=2048, activation='tanh', adv_normalization=False, batch_size=64, clip_rate=0.2, debug=False, domain='/home/nicole/MIT Dropbox/Ngoc La/PhD/Projects/HDDLGym_developing_rebuttal/HDDLGym_dev/HDDL_files/Overcooked_specialization/overcooked_short_domain.hddl', dvc=device(type='cpu'), entropy_coef=0.01, entropy_coef_decay=0.99, epsilon=1.0, eval_interval=1000.0, gamma=0.99, l2_reg=0, lambd=0.95, lr=0.0001, max_episode=50, max_step=25, net_width=64, planner_time_limit=5, problem='/home/nicole/MIT Dropbox/Ngoc La/PhD/Projects/HDDLGym_developing_rebuttal/HDDLGym_dev/HDDL_files/Overcooked_specialization/overcooked_short_prob2.hddl', render=False, save_interval=1000.0, seed=209, use_central_planner=False, write=False)\n",
      "/home/nicole/MIT Dropbox/Ngoc La/PhD/Projects/HDDLGym_developing_rebuttal/HDDLGym_dev/HDDL_files/Overcooked_specialization/overcooked_short_prob2.hddl\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"main_train.py\", line 313, in <module>\n",
      "    main_train(opt, debug=opt.debug)\n",
      "  File \"main_train.py\", line 64, in main_train\n",
      "    eval_env = HDDLEnv(opt.domain, opt.problem)\n",
      "  File \"/home/nicole/MIT Dropbox/Ngoc La/PhD/Projects/HDDLGym_developing_rebuttal/HDDLGym_dev/hddl_env.py\", line 13, in __init__\n",
      "    self.env_dictionary = main_parser(domain_file, problem_file)\n",
      "  File \"/home/nicole/MIT Dropbox/Ngoc La/PhD/Projects/HDDLGym_developing_rebuttal/HDDLGym_dev/hddl_parser.py\", line 83, in main_parser\n",
      "    gp = lp.generate_grounded_predicate(type_object_dict)\n",
      "  File \"/home/nicole/MIT Dropbox/Ngoc La/PhD/Projects/HDDLGym_developing_rebuttal/HDDLGym_dev/hddl_utils.py\", line 646, in generate_grounded_predicate\n",
      "    grounded_predicate_list.append(self.print_grounded_predicate(l))\n",
      "  File \"/home/nicole/MIT Dropbox/Ngoc La/PhD/Projects/HDDLGym_developing_rebuttal/HDDLGym_dev/hddl_utils.py\", line 630, in print_grounded_predicate\n",
      "    ans = ans + ' ' + str(i)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Call the default main_train.py:\n",
    "!python3 main_train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e11cbe-3682-4a14-8bc5-ba5010bc2341",
   "metadata": {},
   "source": [
    "# 5 Deploy RL policy\n",
    "The section guides you through training a PPO model, running a rollout, and visualizing the results using a local server.\n",
    "- Run the trained model and record the plan\n",
    "- Visualize the hierarchical plan\n",
    "\n",
    "[back to top](#HDDLGym-Tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8bb07e0-a0d4-4705-b61a-e9bd773659d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(K_epochs=10, Loadmodel=False, Max_train_steps=50000000.0, Model=2, T_horizon=2048, activation='tanh', adv_normalization=False, batch_size=64, clip_rate=0.2, debug=False, domain='/home/nicole/MIT Dropbox/Ngoc La/PhD/Projects/HDDLGym_developing_rebuttal/HDDLGym_dev/HDDL_files/Overcooked_specialization/overcooked_short_domain.hddl', dvc=device(type='cpu'), entropy_coef=0.01, entropy_coef_decay=0.99, epsilon=1.0, eval_interval=1000.0, gamma=0.99, l2_reg=0, lambd=0.95, lr=0.0001, max_episode=50, max_step=25, net_width=64, planner_time_limit=5, problem='/home/nicole/MIT Dropbox/Ngoc La/PhD/Projects/HDDLGym_developing_rebuttal/HDDLGym_dev/HDDL_files/Overcooked_specialization/overcooked_short_prob2.hddl', render=False, save_interval=1000.0, seed=209, use_central_planner=False, write=False)\n",
      "Namespace(K_epochs=10, Loadmodel=False, Max_train_steps=50000000.0, Model=2, T_horizon=2048, activation='tanh', adv_normalization=False, batch_size=64, clip_rate=0.2, debug=False, domain='/home/nicole/MIT Dropbox/Ngoc La/PhD/Projects/HDDLGym_developing_rebuttal/HDDLGym_dev/HDDL_files/Overcooked_specialization/overcooked_short_domain.hddl', dvc=device(type='cpu'), entropy_coef=0.01, entropy_coef_decay=0.99, epsilon=1.0, eval_interval=1000.0, gamma=0.99, l2_reg=0, lambd=0.95, lr=0.0001, max_episode=50, max_step=25, net_width=64, planner_time_limit=5, problem='/home/nicole/MIT Dropbox/Ngoc La/PhD/Projects/HDDLGym_developing_rebuttal/HDDLGym_dev/HDDL_files/Overcooked_specialization/overcooked_short_prob2.hddl', render=False, save_interval=1000.0, seed=209, use_central_planner=False, write=False)\n",
      "/home/nicole/MIT Dropbox/Ngoc La/PhD/Projects/HDDLGym_developing_rebuttal/HDDLGym_dev/HDDL_files/Overcooked_specialization/overcooked_short_prob2.hddl\n",
      "opt.state_dim: 126\n",
      "opt.action_dim: 36\n",
      "Random Seed: 209\n",
      "Env: /home/nicole/MIT Dropbox/Ngoc La/PhD/Projects/HDDLGym_developing_rebuttal/HDDLGym_dev/HDDL_files/Overcooked_specialization/overcooked_short_prob2.hddl   state_dim: 126   action_dim: 36    Random Seed: 209   max_e_steps: 25\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Episode 0 ***\n",
      "-- total train steps: 0\n",
      "Average step of successfull episodes: 0\n",
      "number of successful ep 0\n",
      "\n",
      "\n",
      "*** Episode 10 ***\n",
      "-- total train steps: 153\n",
      "Average step of successfull episodes: 16.3\n",
      "number of successful ep 10\n",
      "\n",
      "\n",
      "*** Episode 20 ***\n",
      "-- total train steps: 304\n",
      "Average step of successfull episodes: 16.2\n",
      "number of successful ep 20\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"main_train.py\", line 313, in <module>\n",
      "    main_train(opt, debug=opt.debug)\n",
      "  File \"main_train.py\", line 139, in main_train\n",
      "    ag.decentralize_planner_agent(env, belief_other_agents = belief_other_agents,agent_policy = policy,\\\n",
      "  File \"/home/nicole/MIT Dropbox/Ngoc La/PhD/Projects/HDDLGym_developing_rebuttal/HDDLGym_dev/agent_class.py\", line 123, in decentralize_planner_agent\n",
      "    list_agents = centralized_planner(world, main_agent_index = 0,all_agents = list_agents, all_policies = policy_list, debug=debug,\\\n",
      "  File \"/home/nicole/MIT Dropbox/Ngoc La/PhD/Projects/HDDLGym_developing_rebuttal/HDDLGym_dev/central_planner.py\", line 88, in centralized_planner\n",
      "    valid_op_list, empty_by_others = generate_valid_operators(world, agent, print_empty_by_others=True)\n",
      "  File \"/home/nicole/MIT Dropbox/Ngoc La/PhD/Projects/HDDLGym_developing_rebuttal/HDDLGym_dev/central_planner_utils.py\", line 353, in generate_valid_operators\n",
      "    valid_op_list, empty_by_others = choose_subtask_policy(world.env_dictionary, world.current_state, method_str=agent.task_method_hierarchy[-1], agent=agent, subtask_policy = agent.agent_policy,\\\n",
      "  File \"/home/nicole/MIT Dropbox/Ngoc La/PhD/Projects/HDDLGym_developing_rebuttal/HDDLGym_dev/central_planner_utils.py\", line 242, in choose_subtask_policy\n",
      "    _m_list = choose_method_policy(env_dictionary, state, sub, agent, method_policy=None, print_valid_list=True, debug=False)\n",
      "  File \"/home/nicole/MIT Dropbox/Ngoc La/PhD/Projects/HDDLGym_developing_rebuttal/HDDLGym_dev/central_planner_utils.py\", line 103, in choose_method_policy\n",
      "    if lifted_methods_list[i].precondition.check_precondition(state, var_obj_dict, debug=debug) and grounded_methods_list[i][j] not in agent.infeasible_task_method:\n",
      "  File \"/home/nicole/MIT Dropbox/Ngoc La/PhD/Projects/HDDLGym_developing_rebuttal/HDDLGym_dev/hddl_utils.py\", line 1266, in check_precondition\n",
      "    return self.grounded_precondition_literal.check_literal(state,debug=debug)\n",
      "  File \"/home/nicole/MIT Dropbox/Ngoc La/PhD/Projects/HDDLGym_developing_rebuttal/HDDLGym_dev/hddl_utils.py\", line 1345, in check_literal\n",
      "    if not element.check_literal(state, debug=debug):\n",
      "  File \"/home/nicole/MIT Dropbox/Ngoc La/PhD/Projects/HDDLGym_developing_rebuttal/HDDLGym_dev/hddl_utils.py\", line 1367, in check_literal\n",
      "    if self.literal_str not in state and debug:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Train the Model\n",
    "# This will generate model files like ppo_actor1000.pth and ppo_critic1000.pth in the 'model/' directory\n",
    "!python3 main_train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af1f582",
   "metadata": {},
   "source": [
    "## 5.1: Run the HDDL Model\n",
    "Specify the exact model you want to use for the rollout by setting `opt.model`.\n",
    "For example, to use `ppo_actor2.pth` and `ppo_critic2.pth`:\n",
    "\n",
    "[back to top](#HDDLGym-Tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95ed34a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2140.00s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(K_epochs=10, Loadmodel=False, Max_train_steps=50000000.0, Model=2, T_horizon=2048, activation='tanh', adv_normalization=False, batch_size=64, clip_rate=0.2, debug=False, domain='/home/rumon/dev/HDDLGym_dev/HDDL_files/Overcooked_specialization/overcooked_short_domain.hddl', dvc=device(type='cpu'), entropy_coef=0.01, entropy_coef_decay=0.99, epsilon=1.0, eval_interval=1000.0, gamma=0.99, l2_reg=0, lambd=0.95, lr=0.0001, max_episode=50, max_step=25, net_width=64, planner_time_limit=5, problem='/home/rumon/dev/HDDLGym_dev/HDDL_files/Overcooked_specialization/overcooked_short_prob2.hddl', render=False, save_interval=1000.0, seed=209, use_central_planner=False, write=False)\n",
      "/home/rumon/dev/HDDLGym_dev/learning_methods.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.critic.load_state_dict(torch.load(str(script_dir / \"model/ppo_critic{}.pth\").format(episode)))\n",
      "/home/rumon/dev/HDDLGym_dev/learning_methods.py:415: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.actor.load_state_dict(torch.load(str(script_dir / \"model/ppo_actor{}.pth\").format(episode)))\n",
      "start evaluating policy ...\n",
      "action_dict {'chef1': 'none chef1', 'chef2': 'a-interact chef2 onion-pile empty onion onion onion'}\n",
      "action_dict {'chef1': 'none chef1', 'chef2': 'a-interact chef2 pot1 onion empty empty onion-1'}\n",
      "action_dict {'chef1': 'none chef1', 'chef2': 'a-interact chef2 pot1 empty empty onion-1 cooking-soup-1-onion'}\n",
      "action_dict {'chef1': 'a-interact chef1 bowl-pile empty bowl bowl bowl', 'chef2': 'none chef2'}\n",
      "action_dict {'chef1': 'wait chef1 pot1 cooking-soup-1-onion-stage3 cooking-soup-1-onion-stage4', 'chef2': 'none chef2'}\n",
      "action_dict {'chef1': 'none chef1', 'chef2': 'none chef2'}\n",
      "action_dict {'chef1': 'a-interact chef1 pot1 bowl soup-1-onion soup-1-onion empty', 'chef2': 'none chef2'}\n",
      "action_dict {'chef1': 'a-interact chef1 delivery soup-1-onion empty empty soup-1-onion', 'chef2': 'none chef2'}\n",
      "Evaluation turn 0 completed ['make-soup soup-1-onion delivery'] after 8 steps, getting score of 84\n",
      "\n",
      "Hierarchies Record for turn  0\n",
      "[['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'add-ingredient pot1 onion onion-1', 'm-add-ingredient-1-onion pot1 onion onion-pile onion-1 empty', 'none chef1'], ['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'add-ingredient pot1 onion onion-1', 'm-add-ingredient-1-onion pot1 onion onion-pile onion-1 empty', 't-interact chef2 onion-pile onion onion', 'm-interact-direct chef2 onion-pile empty onion onion onion', 'a-interact chef2 onion-pile empty onion onion onion']]\n",
      "--\n",
      "{'chef1': 'none chef1', 'chef2': 'a-interact chef2 onion-pile empty onion onion onion'}\n",
      "[['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'add-ingredient pot1 onion onion-1', 'm-add-ingredient-1-onion pot1 onion onion-pile onion-1 empty', 'none chef1'], ['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'add-ingredient pot1 onion onion-1', 'm-add-ingredient-1-onion pot1 onion onion-pile onion-1 empty', 't-interact chef2 pot1 empty onion-1', 'm-interact-direct chef2 pot1 onion empty empty onion-1', 'a-interact chef2 pot1 onion empty empty onion-1']]\n",
      "--\n",
      "{'chef1': 'none chef1', 'chef2': 'a-interact chef2 pot1 onion empty empty onion-1'}\n",
      "[['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'cook pot1 onion-1 cooking-soup-1-onion', 'm-cook pot1 onion-1 cooking-soup-1-onion chef1 empty', 'none chef1'], ['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'cook pot1 onion-1 cooking-soup-1-onion', 'm-cook pot1 onion-1 cooking-soup-1-onion chef2 empty', 'a-interact chef2 pot1 empty empty onion-1 cooking-soup-1-onion']]\n",
      "--\n",
      "{'chef1': 'none chef1', 'chef2': 'a-interact chef2 pot1 empty empty onion-1 cooking-soup-1-onion'}\n",
      "[['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 't-interact chef1 bowl-pile bowl bowl', 'm-interact-direct chef1 bowl-pile empty bowl bowl bowl', 'a-interact chef1 bowl-pile empty bowl bowl bowl'], ['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 'none chef2']]\n",
      "--\n",
      "{'chef1': 'a-interact chef1 bowl-pile empty bowl bowl bowl', 'chef2': 'none chef2'}\n",
      "[['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 't-wait-cooking chef1 pot1 soup-1-onion', 'm-still-wait-cooking chef1 pot1 soup-1-onion cooking-soup-1-onion-stage3 cooking-soup-1-onion-stage4', 'wait chef1 pot1 cooking-soup-1-onion-stage3 cooking-soup-1-onion-stage4'], ['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 'none chef2']]\n",
      "--\n",
      "{'chef1': 'wait chef1 pot1 cooking-soup-1-onion-stage3 cooking-soup-1-onion-stage4', 'chef2': 'none chef2'}\n",
      "[['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 't-wait-cooking chef1 pot1 soup-1-onion', 'm-still-wait-cooking chef1 pot1 soup-1-onion cooking-soup-1-onion-stage3 cooking-soup-1-onion-stage4', 'none chef1'], ['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 'none chef2']]\n",
      "--\n",
      "{'chef1': 'none chef1', 'chef2': 'none chef2'}\n",
      "[['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 't-interact chef1 pot1 soup-1-onion empty', 'm-interact-direct chef1 pot1 bowl soup-1-onion soup-1-onion empty', 'a-interact chef1 pot1 bowl soup-1-onion soup-1-onion empty'], ['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 'none chef2']]\n",
      "--\n",
      "{'chef1': 'a-interact chef1 pot1 bowl soup-1-onion soup-1-onion empty', 'chef2': 'none chef2'}\n",
      "[['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 't-interact chef1 delivery empty soup-1-onion', 'm-interact-direct chef1 delivery soup-1-onion empty empty soup-1-onion', 'a-interact chef1 delivery soup-1-onion empty empty soup-1-onion'], ['make-soup soup-1-onion delivery', 'm-make-soup soup-1-onion pot1 delivery onion onion-1 cooking-soup-1-onion', 'deliver soup-1-onion delivery', 'm-deliver pot1 delivery bowl-pile soup-1-onion bowl empty', 'none chef2']]\n",
      "--\n",
      "{'chef1': 'a-interact chef1 delivery soup-1-onion empty empty soup-1-onion', 'chef2': 'none chef2'}\n",
      "Episode reward of evaluating episode 0 is 84\n",
      "Evaluation Score for /home/rumon/dev/HDDLGym_dev/HDDL_files/Overcooked_specialization/overcooked_short_prob2.hddl: 84\n"
     ]
    }
   ],
   "source": [
    "# Run the rollout with the specified model\n",
    "# Replace '2' with the desired model number\n",
    "!python3 run_hddl_policy.py --Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02062b6",
   "metadata": {},
   "source": [
    "# 5.2: Launch the Local Server\n",
    "The generated data will be dumped into `website/data.json`. To visualize the data, navigate to the website folder and start a local server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa08c590",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2123.23s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving HTTP on 0.0.0.0 port 8000 (http://0.0.0.0:8000/) ...\n",
      "127.0.0.1 - - [04/Feb/2025 14:00:44] \"GET / HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Feb/2025 14:00:44] \"GET /styles.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Feb/2025 14:00:44] \"GET /script.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Feb/2025 14:00:44] \"GET /data.json HTTP/1.1\" 200 -\n",
      "^C\n",
      "\n",
      "Keyboard interrupt received, exiting.\n"
     ]
    }
   ],
   "source": [
    "# Launch the local server on port 8000\n",
    "!python3 -m http.server 8000 --directory website\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82302964",
   "metadata": {},
   "source": [
    "# 6 [Extra] \n",
    "# Overcooked Policy Visualization Tutorial\n",
    "\n",
    "This section will guide you through the process of visualizing the Overcooked policy using Docker and Docker Compose. This has been tested on **Ubuntu 20.04**.\n",
    "\n",
    "**Prerequisites:**  \n",
    "- Docker and Docker Compose must be installed on your system.\n",
    "\n",
    "\n",
    "#### Setting Up the Environment\n",
    "\n",
    "**Step 1: Navigate to the Project Directory**\n",
    "\n",
    "Open your terminal and navigate to the `overcooked_demo` directory:\n",
    "\n",
    "```bash\n",
    "cd ../overcooked/src/overcooked_demo\n",
    "```\n",
    "\n",
    "**Step 2: Create the `.env` File**\n",
    "\n",
    "Create a `.env` file and add the following environment variables:\n",
    "\n",
    "```bash\n",
    "GITHUB_TOKEN=<YOUR-GITHUB-TOKEN>\n",
    "REPO_URL=<GITHUB-URL-OF-THIS-REPO>\n",
    "FLASK_SECRET_KEY=<FLASK-SECRET-KEY>\n",
    "```\n",
    "\n",
    "Example:\n",
    "\n",
    "```bash\n",
    "GITHUB_TOKEN=ghp_example1234567890\n",
    "REPO_URL=github.com/HDDLGym/HDDLGym.git\n",
    "FLASK_SECRET_KEY=myflasksecretkey123\n",
    "```\n",
    "\n",
    "\n",
    "#### Building and Running the Docker Containers\n",
    "\n",
    "**Step 3: Navigate to the Server Directory**\n",
    "\n",
    "```bash\n",
    "cd ../overcooked_demo/server\n",
    "```\n",
    "\n",
    "**Step 4: Build the Docker Image**\n",
    "\n",
    "Use the following command to build the Docker image:\n",
    "\n",
    "```bash\n",
    "sudo docker compose build\n",
    "```\n",
    "\n",
    "> ⚠️ **Note:** The build process may take over **1300 seconds** (~20 minutes), depending on your system.\n",
    "\n",
    "**Step 5: Start the Docker Containers**\n",
    "\n",
    "After the build is complete, start the containers:\n",
    "\n",
    "```bash\n",
    "sudo docker compose up\n",
    "```\n",
    "\n",
    "\n",
    "#### Visualizing the Overcooked Policy\n",
    "\n",
    "Once the container is up and running:\n",
    "\n",
    "1. Open your web browser.\n",
    "2. Navigate to: [http://localhost/experiment](http://localhost/experiment)\n",
    "\n",
    "You should now be able to view the **rollout/2D visualization** of the Overcooked policy.\n",
    "\n",
    "\n",
    "#### Troubleshooting\n",
    "\n",
    "- **Docker Build Fails:** Ensure Docker and Docker Compose are properly installed and updated.\n",
    "- **Cannot Access the Visualization:** Confirm that the Docker container is running without errors and the `.env` file is correctly configured.\n",
    "\n",
    "[back to top](#HDDLGym-Tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0c2704-1be9-400d-ab02-6a05ac35cefc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
